---
title: "Charting missingness"
subtitle: "An adventure through graph theory"
author: "Jonathan Marshall"
output:
  xaringan::moon_reader:
    css: [default, default-fonts, "custom.css"]
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"
    nature:
      highlightStyle: tomorrow
      highlightLines: true
      countIncrementalSlides: false
      ratio: "16:9"
      slideNumberFormat: |
        <div class="progress-bar-container">
          <div class="progress-bar" style="width: calc(%current% / %total% * 100%);" />
        </div>
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(tidyverse)
library(Manu)
library(colorspace)

theme_set(theme_minimal(base_size=13))
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      fig.retina = 3, fig.align='center',
                      fig.dim=c(4.8,4.8), out.width='100%', dev.args=list(bg="transparent"))

# Load our distance data
hg_dist <- read_csv("data/distance.csv")

# Load some data
max_genes <- read_csv("data/max_genes_by_distance.csv") |>
  mutate(dist_to_nearest = as_factor(dist_to_nearest) |> fct_rev()) |>
  mutate(sum = humans+genes, prod=humans*genes) |> 
  group_by(dist_to_nearest) |>
  mutate(max_sum = sum == max(sum), max_prod = prod == max(prod),
         max_equal = humans == genes) |>
  ungroup()

plot_right <- ggplot(max_genes) +
  geom_line(aes(x=humans, y=genes, col=dist_to_nearest, size=dist_to_nearest == 0)) +
  scale_colour_manual(values=c(scales::alpha(get_pal('Hoiho')[-3], 0.7), 'black')) +
  scale_size_manual(values=c(0.5, 1)) +
  guides(size='none', col=guide_legend(nrow=1)) +
  labs(x="Number of humans",
       y="Number of genes",
       col="SNPs") +
  theme(legend.position='bottom')

plot_dark <- plot_right +
  theme(rect = element_rect(fill='transparent'),
        #panel.background = element_rect(fill='transparent'),
        panel.grid = element_line(colour='grey30'),
        text = element_text(colour='white'),
        axis.text = element_text(colour='white')) +
  scale_colour_manual(values=c(get_pal('Hoiho')[-3], 'white')) +
  scale_size_manual(values=c(0.8, 1))

data <- list(humans = 651,
             sources = 560,
             genes = 1343)
```

class: middle, inverse

# The chart

```{r, fig.dim=c(7,5), out.width='70%', fig.align='center'}
plot_dark
```

---

## Source attribution

- PhD student Helen Smith is looking at using random forests for the classification problem of **source attribution**.

- We have isolates of *Campylobacter* collected from `r data$humans` people across the Auckland and Manawatu regions.

- At the same time isolates of were sampled from `r data$sources` hosts of *Campylobacter* (chickens, cows, sheep).

- These were whole-genome sequenced, and the goal is to assign each
human isolate to the most likely source.

- Source isolates are our training data, and human isolates are the test set.

---

## Data

- We have `r data$genes` genes as predictors variables. Each isolate has a potentially different version (**allele**) of each gene.

- Many genes are highly diverse. Range from 3-164 different alleles, median 48.

- Many alleles are seen in only one isolate.

- Many alleles are seen in only one **human** isolate.

- In terms of a classification problem:

    - We have a large number of categorical predictors.
    - The predictors each have a large number of levels.
    - Many levels in the test set are not in the training set (**absent levels**).

---

.left-code-wide[
## Dealing with absent levels

- Treat the absent levels in humans as missing.

- With a tree or forest, we might be OK.

    - Could use 'surrogate splits' for a tree.
    - Some of the trees in the forest may not use the absent level(s).

- What if we try and remove the missingness?

    - How many humans and/or genes would be retained?

]

.right-plot-narrow[
```{r, fig.dim=c(3.6,4.8)}
hg_dist |>
  rowid_to_column("human") |>
  pivot_longer(-human, names_to="gene", values_to="count") |>
  mutate(count = count > 0) |>
  ggplot() +
  geom_raster(aes(x=human, y=gene, fill=count)) +
  scale_fill_manual(values=c("transparent", "black")) +
  theme_void() +
  guides(fill='none')
```
]
---

.left-code[
## The chart

- Suppose we want to remove all the absent levels.

- And we want to retain $h$ human samples.

- What is the maximum number of genes $g(h)$ that we can
retain?

]

.right-plot[
```{r}
plot_right
```
]

---

.left-code[
## The chart

- Suppose we want to remove all the absent levels.

- And we want to retain $h$ human samples.

- What is the maximum number of genes $g(h)$ that we can
retain?

- The other lines are where we allow two sequences to be treated the same if the sequences are close.

- **We can use many more genes if we allow just one SNP difference in sequences.**
]

.right-plot[
```{r}
plot_right
```
]

---

## The chart

How do we find the maximum number of genes $g(h)$ for a given number of human cases $h$?

Let $G_i$ be the set of genes for which human $i$ has previously seen alleles. i.e. $G \setminus G_i$ is the set of absent levels.

Need to find the set $H_0 \subseteq H$ that maximises the size $g(h) = |G_0|$ of $G_0 = \bigcap_{i\in H_0} G_i$.

i.e. $H_0$ is the set of $h$ humans that have no absent alleles across $G_0$ genes such that $G_0$ is as large as possible.

---

## Finding $H_o$

Clearly enumerating all sets $H_0$ of size $h$ is going to be much too time consuming.

One idea is to start with the $H_0$ containing the $h$ humans with fewest absent levels and find the corresponding genes $G_0$.

But there's no evidence this will be optimal.

--

e.g. consider

```{r}
simple <- tribble(~row,~g1,~g2,~g3,~g4,
        1,'-', 'a', 'a','a',
        2,'a', '-', '-', 'a',
        3,'b', '-', '-', 'a')
simple |>
  knitr::kable()
```

row 1 has the fewest absent levels, yet rows 2 and 3 should be used with $h=2$.

This also holds for genes - the most complete gene may not be in the set $G_0$.

---

## What about a graph?

What we're wanting to do is remove a set of rows (humans) and columns (genes) from our data matrix such that the result has no absent alleles.

There is a closely related problem in graph theory: Finding a set of vertices such that removing the vertices removes all edges.

Perhaps we can use that!

---

class: middle, inverse

# Some graph theory

---

## The graph

Treat each human and each gene as a vertex in a graph.

Each human is connected to a gene where they have an absent level.

This will form a **bipartite graph** $B=\{H, G, E\}$ with vertex set $V=H \cup G$ and edge set $E = \{(h,g) | h \in H\mbox{ has an absent level for variable }g \in G\}$

.left-code[
Our previous example:
```{r}
simple |> knitr::kable()
```
]

.right-plot[
```{r, fig.dim=c(4,1.5)}
library(igraph)
par(mai=rep(0,4))
graph <- simple |> pivot_longer(-row) |> filter(value != '-') |> mutate(row = paste0('h', row)) |> select(-value) |>
  as.matrix() |>
  graph_from_edgelist(directed=FALSE)

cols <- c("thistle", "wheat2")
V(graph)$type <- substring(V(graph)$name,1,1) == "g"
V(graph)$color <- cols[(substring(V(graph)$name,1,1) == "h")+1]

g2 <- graph |> complementer()
ge <- expand_grid(a=paste0("g", 1:4), b=paste0("g", 1:4)) |>
  filter(a != b) |>
  mutate(c=paste(a,b,sep="|")) |> pull(c)
he <- expand_grid(a=paste0("h", 1:3), b=paste0("h", 1:3)) |>
  filter(a != b) |>
  mutate(c=paste(a,b,sep="|")) |> pull(c)

g2 <- g2 |> delete_edges(c(ge, he))

g2 |>
  plot(layout=layout_as_bipartite, vertex.label.color='black', vertex.size = 30, asp = 0.4, margin=0.2)
```
]

---

## Vertex covers

A **vertex cover** is a set of vertices such that all edges in the graph are incident on one or more vertex in the set.

A **minimum vertex cover** is the smallest vertex cover. Finding this is a well known problem that can be done in polynomial time - we'll see how soon.

For our chart, we want a **constrained** vertex cover: Not just the smallest, though that will be at least one of the points on our chart, but we wish to ensure that a certain number of human vertices are included in the vertex cover.

It turns out that this is a well studied problem too!

---

## Constrained bipartite vertex covers

Suppose we have a bipartite graph $B = \{H, G, E\}$ where $H$ and $G$ are disjoint vertex sets and $E$ is the edge set connecting vertices in $H$ to vertices in $G$.

The **constrained bipartite vertex cover problem** asks whether there exists a vertex cover for $B$ containing at most $k_H$ vertices in $H$ and $k_G$ vertices in $G$.

This problem arises in reconfigurable memory arrays which have a set of $k_H$ spare rows and $k_G$ spare columns that can be used to replace rows and columns that contain faults.

This is exactly what we need for our chart: Set $k_H = |H| - h$. If a cover exists for $k_G = |G| - g$ but no cover exists for $k_G = |G| - (g + 1)$ then the pair $(h,g)$ is on our curve.

---

## Example

.left-half[
If $h=1$ we have a cover with  $g=3$ using the set $\{\mbox{h2}, \mbox{h3}, \mbox{g1}\}$, but no cover exists with $g=4$. 

```{r, fig.dim=c(4,1.5), fig.align='center', out.width='100%'}
par(mai=c(0.1, 0, 0.1, 0))

g2 |>
  set_edge_attr('color', value='grey80') |>
  set_vertex_attr('color', index=c('h2', 'h3'), value=lighten('wheat', 0.9)) |>
  set_vertex_attr('color', index=c('g1'), value=lighten('thistle', 0.9)) |>
  set_vertex_attr('frame.color', value='black') |>
  set_vertex_attr('frame.color', index=c('g1', 'h2', 'h3'), 'grey70') |>
  set_vertex_attr('label.color', value='black') |>
  set_vertex_attr('label.color', index=c('g1', 'h2', 'h3'), value='grey70') |>
  plot(layout=layout_as_bipartite, vertex.size = 30, asp = 0.4, margin=0.2)
```

Thus $(h,g)=(1,3)$ will be on the curve for this graph.
]

.right-half[
If $h=2$ we have a cover with $g=2$ using the set $\{\mbox{h1}, \mbox{g2}, \mbox{g3}\}$, but no cover exists with $g=3$.

```{r, fig.dim=c(4,1.5), fig.align='center', out.width='100%'}
par(mai=c(0.1, 0, 0.1, 0))

g2 |>
  set_edge_attr('color', value='grey80') |>
  set_vertex_attr('color', index=c('h1'), value=lighten('wheat', 0.9)) |>
  set_vertex_attr('color', index=c('g2', 'g3'), value=lighten('thistle', 0.9)) |>
  set_vertex_attr('frame.color', value='black') |>
  set_vertex_attr('frame.color', index=c('g2', 'g3', 'h1'), 'grey70') |>
  set_vertex_attr('label.color', value='black') |>
  set_vertex_attr('label.color', index=c('g2', 'g3', 'h1'), value='grey70') |>
  plot(layout=layout_as_bipartite, vertex.size = 30, asp = 0.4, margin=0.2)
```

Thus $(h,g)=(2,2)$ will be on the curve.
]
---

## NP-complete

Unfortunately, the constrained vertex cover problem is **NP-complete**.

But the graph is relatively sparse, so perhaps computation time is feasible.

There are algorithms available, but no ready to use code.

The minimal vertex cover problem is often attacked using integer programming, so that might be a good way to go here.

---

## The integer program for minimum vertex cover

Let $V = H \cup G$ be the vertex set of the bipartite graph $B$ and introduce indicators
$$x_i = \left\{\begin{align}1, & \mbox{ if }v_i \in V\mbox{ is in the vertex cover}\\0,&\mbox{ otherwise.}\end{align}\right.$$

Let $A$ be the **incidence matrix** of $B$ such that rows of $A$ represent vertices and columns represent edges with $A_{ik} = 1$ if edge $k$ is incident on vertex $i$, and $A_{ik}=0$ otherwise.

Then the minimum vertex cover problem translates to the integer program:

$$\begin{align}\mbox{minimise } &\sum_{i=1}^{|V|} x_i\\\mbox{such that } & A^T \mathbf{x} \geq \mathbf{1},\\ &x_i \in \{0, 1\}, i=1,\ldots, |V|.\end{align}$$

---

## The integer program for minimum vertex cover

The corresponding *relaxed* linear program:
$$\begin{align}\mbox{minimise } &\sum_{i=1}^{|V|} x_i\\\mbox{such that } & A^T \mathbf{x} \geq 1,\\ & \mathbf{x} \geq \mathbf{0},\end{align}$$
can be solved using the simplex algorithm in polynomial time.

If the solutions to the relaxed linear program are integral they also solve the integer program and find a minimum vertex cover.

We can guarantee this if $A^T$ is a **totally unimodular matrix**.

---

## Totally unimodular matrices

A matrix $A$ is **totally unimodular** if and only if all square submatrices $S$ have $\det(S) \in \{-1, 0, 1\}$.

We use the following two results:

**Theorem 1**
Solutions to the linear program above are integral if $A$ is totally unimodular and the RHS of the constraints is integral.

**Theorem 2**
The incidence matrix of a bipartite graph is totally unimodular.

Thus, solutions to the linear program give the minimum vertex cover in polynomial time.

---

## What about constrained vertex covers?

To get our chart we need to add the constraint
$$
\sum_{v_i \in H} x_i \leq |H|-h.
$$
This can be done by appending a row to $A^T$ with -1 for humans and 0 for genes.

The resulting matrix may not be totally unimodular. Consider vertices h2, h3 and g2 from our earlier example. The $3\times 3$ matrix formed by this subgraph and the constraint row has determinant -2:

.left-half[
```{r, fig.dim=c(4,1.5), fig.align='center', out.width='100%'}
par(mai=c(0.1, 0, 0.1, 0))

subg <- E(g2, path=c('h2', 'g2', 'h3'))
g2 |>
  set_edge_attr('color', value='grey80') |>
  set_edge_attr('color', index=subg, value='black') |>
  set_edge_attr('label', index=subg, value=c('f', 'e')) |>
  set_edge_attr('label.x', index=subg, value=c(-0.4,0.05)) |>
  set_edge_attr('label.y', index=subg, value=c(0.1,-0.2)) |>
  set_vertex_attr('color', index='h1', value=lighten('wheat', 0.9)) |>
  set_vertex_attr('color', index=c('g1', 'g3', 'g4'), value=lighten('thistle', 0.9)) |>
#  set_vertex_attr('color', index=c('g1'), value='thistle') |>
  set_vertex_attr('frame.color', value='grey60') |>
  set_vertex_attr('frame.color', index=c('g2', 'h2', 'h3'), 'black') |>
  set_vertex_attr('label.color', value='grey60') |>
  set_vertex_attr('label.color', index=c('g2', 'h2', 'h3'), value='black') |>
  plot(layout=layout_as_bipartite, vertex.size = 30, asp = 0.4, margin=0.2, edge.label.color='black',edge.label.cex=1)
```
]

.right-half[
<br>

$$S = \begin{array}{cc} & \begin{array}{ccc}\small\mbox{h2} & \small\mbox{ h3} & \small\mbox{ g2}\\ \end{array}\\ \begin{array}{c} \small e\\ \small f\\\ \small \end{array} & \left[\begin{array}{c c c} 0 & 1 & 1\\1 & 0 & 1\\-1 &-1 &0\end{array}\right]\end{array}, \quad \det(S) = -2.$$
]

---

## Still NP-complete, but we can use LEGO

While it won't be solvable in polynomial time, at least we can use existing stuff:

```{r, eval=FALSE, echo=TRUE}
library(ROI)
library(ROI.plugin.glpk)

incidence <- matrix(0, nrow=H+G, ncol=nrow(E))
incidence[cbind(E[,1]    , 1:nrow(E))] <- 1
incidence[cbind(E[,2] + H, 1:nrow(E))] <- 1

objective <- L_objective(L = c(rep(0, H), rep(1, G)))
constraint1 <- L_constraint(L = t(incidence), dir = rep('>=', nrow(E)), rhs = rep(1, nrow(E)))
constraint2 <- L_constraint(L = matrix(c(rep(1, H), rep(0, G)), nrow=1), dir = "<=", rhs=H - h)
lp <- OP(objective, c(constraint1, constraint2, types = rep("B", H+G), maximum=FALSE)
ROI_solve(lp, solver="glpk")
```

It took 16 hours on my laptop to run for all possible $h$.

Good enough!

---

class: middle, inverse

# Questions?

```{r, fig.dim=c(7,5), out.width='70%', fig.align='center'}
plot_dark
```
